{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a8a7a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<h2>Homework - Hyperparameter Tuning</h2>\n",
    "<h4>DAT-5303 | Machine Learning</h4>\n",
    "\n",
    "<br>\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d6d3d",
   "metadata": {},
   "source": [
    "Team: TEAM 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb8e6f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<br>\n",
    "In this homework, your team is tasked with tuning the hyperparameters of two of the following model types:\n",
    "\n",
    "* Regression Tree\n",
    "* Random Forest\n",
    "* Gradient Boosted Machine (GBM)\n",
    "\n",
    "<h3>Step 1: Imports</h3>\n",
    "Import the following packages and make sure to start replacing my comments with your own. Also, please tell me about which models you are tuning in the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7173da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing library which we need in this analysis\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "import numpy             as np\n",
    "\n",
    "# importing model types\n",
    "import sklearn.linear_model                            # import sklearn linear model \n",
    "from sklearn.tree     import DecisionTreeRegressor     # import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor     # import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor # import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# importing train_test_split and import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split   \n",
    "from sklearn.model_selection import RandomizedSearchCV \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0099269b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa5de1b5",
   "metadata": {},
   "source": [
    "Which models are you tuning?\n",
    "\n",
    "DecisionTreeRegressor\n",
    "RandomForestRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38912633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Overall_Qual</th>\n",
       "      <th>Overall_Cond</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>First_Flr_SF</th>\n",
       "      <th>Second_Flr_SF</th>\n",
       "      <th>Gr_Liv_Area</th>\n",
       "      <th>Full_Bath</th>\n",
       "      <th>...</th>\n",
       "      <th>NoRidge</th>\n",
       "      <th>NridgHt</th>\n",
       "      <th>OldTown</th>\n",
       "      <th>SWISU</th>\n",
       "      <th>Sawyer</th>\n",
       "      <th>SawyerW</th>\n",
       "      <th>Somerst</th>\n",
       "      <th>StoneBr</th>\n",
       "      <th>Timber</th>\n",
       "      <th>Veenker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "      <td>1080</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>1656</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>882</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>1329</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2110</td>\n",
       "      <td>2110</td>\n",
       "      <td>0</td>\n",
       "      <td>2110</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>928</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>1629</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order  Lot_Area  Overall_Qual  Overall_Cond  Mas_Vnr_Area  Total_Bsmt_SF  \\\n",
       "0      1     31770             6             5           112           1080   \n",
       "1      2     11622             5             6             0            882   \n",
       "2      3     14267             6             6           108           1329   \n",
       "3      4     11160             7             5             0           2110   \n",
       "4      5     13830             5             5             0            928   \n",
       "\n",
       "   First_Flr_SF  Second_Flr_SF  Gr_Liv_Area  Full_Bath  ...  NoRidge  NridgHt  \\\n",
       "0          1656              0         1656          1  ...        0        0   \n",
       "1           896              0          896          1  ...        0        0   \n",
       "2          1329              0         1329          1  ...        0        0   \n",
       "3          2110              0         2110          2  ...        0        0   \n",
       "4           928            701         1629          2  ...        0        0   \n",
       "\n",
       "   OldTown  SWISU  Sawyer  SawyerW  Somerst  StoneBr  Timber  Veenker  \n",
       "0        0      0       0        0        0        0       0        0  \n",
       "1        0      0       0        0        0        0       0        0  \n",
       "2        0      0       0        0        0        0       0        0  \n",
       "3        0      0       0        0        0        0       0        0  \n",
       "4        0      0       0        0        0        0       0        0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data / housing_feature_rich file\n",
    "housing = pd.read_excel('./__datasets/housing_feature_rich.xlsx')\n",
    "\n",
    "\n",
    "# define x data variables\n",
    "# drop Sale Price and log sale price\n",
    "x_data = housing.drop(['Sale_Price', 'log_Sale_Price'], axis = 1)\n",
    "\n",
    "\n",
    "# define y data which is sale price\n",
    "y_data = housing.loc[ : , 'Sale_Price']    \n",
    "\n",
    "# show the data\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daaf31f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 2: Train-Test Split</h3>\n",
    "Set up train-test split in the cell below. Set your <em>test_size</em> to 0.25 and your <em>random_state</em> to 219."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf81991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split and devide test size = 0.25 and random state = 219 as instruction \n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x_data,\n",
    "            y_data,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095cc33",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 3: Check Available Hyperparameters</h3>\n",
    "Call help(&nbsp;) on your selected model types to see which hyperparameters are available for tuning. Do NOT tune random_state, n_jobs or anything related to the intercept of a model. Use as many cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92b46eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DecisionTreeRegressor in module sklearn.tree._classes:\n",
      "\n",
      "class DecisionTreeRegressor(sklearn.base.RegressorMixin, BaseDecisionTree)\n",
      " |  DecisionTreeRegressor(*, criterion='squared_error', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, ccp_alpha=0.0)\n",
      " |  \n",
      " |  A decision tree regressor.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <tree>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  criterion : {\"squared_error\", \"friedman_mse\", \"absolute_error\",             \"poisson\"}, default=\"squared_error\"\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"squared_error\" for the mean squared error, which is equal to\n",
      " |      variance reduction as feature selection criterion and minimizes the L2\n",
      " |      loss using the mean of each terminal node, \"friedman_mse\", which uses\n",
      " |      mean squared error with Friedman's improvement score for potential\n",
      " |      splits, \"absolute_error\" for the mean absolute error, which minimizes\n",
      " |      the L1 loss using the median of each terminal node, and \"poisson\" which\n",
      " |      uses reduction in Poisson deviance to find splits.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |          Poisson deviance criterion.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          Criterion \"mse\" was deprecated in v1.0 and will be removed in\n",
      " |          version 1.2. Use `criterion=\"squared_error\"` which is equivalent.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          Criterion \"mae\" was deprecated in v1.0 and will be removed in\n",
      " |          version 1.2. Use `criterion=\"absolute_error\"` which is equivalent.\n",
      " |  \n",
      " |  splitter : {\"best\", \"random\"}, default=\"best\"\n",
      " |      The strategy used to choose the split at each node. Supported\n",
      " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
      " |      the best random split.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=n_features`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the randomness of the estimator. The features are always\n",
      " |      randomly permuted at each split, even if ``splitter`` is set to\n",
      " |      ``\"best\"``. When ``max_features < n_features``, the algorithm will\n",
      " |      select ``max_features`` at random at each split before finding the best\n",
      " |      split among them. But the best found split may vary across different\n",
      " |      runs, even if ``max_features=n_features``. That is the case, if the\n",
      " |      improvement of the criterion is identical for several splits and one\n",
      " |      split has to be selected at random. To obtain a deterministic behaviour\n",
      " |      during fitting, ``random_state`` has to be fixed to an integer.\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the\n",
      " |      (normalized) total reduction of the criterion brought\n",
      " |      by that feature. It is also known as the Gini importance [4]_.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  max_features_ : int\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |         `n_features_` is deprecated in 1.0 and will be removed in\n",
      " |         1.2. Use `n_features_in_` instead.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  tree_ : Tree instance\n",
      " |      The underlying Tree object. Please refer to\n",
      " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      " |      for basic usage of these attributes.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier : A decision tree classifier.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      " |  \n",
      " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      " |  \n",
      " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      " |         Learning\", Springer, 2009.\n",
      " |  \n",
      " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_diabetes\n",
      " |  >>> from sklearn.model_selection import cross_val_score\n",
      " |  >>> from sklearn.tree import DecisionTreeRegressor\n",
      " |  >>> X, y = load_diabetes(return_X_y=True)\n",
      " |  >>> regressor = DecisionTreeRegressor(random_state=0)\n",
      " |  >>> cross_val_score(regressor, X, y, cv=10)\n",
      " |  ...                    # doctest: +SKIP\n",
      " |  ...\n",
      " |  array([-0.39..., -0.46...,  0.02...,  0.06..., -0.50...,\n",
      " |         0.16...,  0.11..., -0.73..., -0.30..., -0.00...])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DecisionTreeRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseDecisionTree\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, criterion='squared_error', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, ccp_alpha=0.0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted='deprecated')\n",
      " |      Build a decision tree regressor from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (real numbers). Use ``dtype=np.float64`` and\n",
      " |          ``order='C'`` for maximum efficiency.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      X_idx_sorted : deprecated, default=\"deprecated\"\n",
      " |          This parameter is deprecated and has no effect.\n",
      " |          It will be removed in 1.1 (renaming of 0.26).\n",
      " |      \n",
      " |          .. deprecated:: 0.24\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : DecisionTreeRegressor\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  n_features_\n",
      " |      DEPRECATED: The attribute `n_features_` is deprecated in 1.0 and will be removed in 1.2. Use `n_features_in_` instead.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  apply(self, X, check_input=True)\n",
      " |      Return the index of the leaf that each sample is predicted as.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array-like of shape (n_samples,)\n",
      " |          For each datapoint x in X, return the index of the leaf x\n",
      " |          ends up in. Leaves are numbered within\n",
      " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      " |          numbering.\n",
      " |  \n",
      " |  cost_complexity_pruning_path(self, X, y, sample_weight=None)\n",
      " |      Compute the pruning path during Minimal Cost-Complexity Pruning.\n",
      " |      \n",
      " |      See :ref:`minimal_cost_complexity_pruning` for details on the pruning\n",
      " |      process.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels) as integers or strings.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. Splits are also\n",
      " |          ignored if they would result in any single class carrying a\n",
      " |          negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ccp_path : :class:`~sklearn.utils.Bunch`\n",
      " |          Dictionary-like object, with the following attributes.\n",
      " |      \n",
      " |          ccp_alphas : ndarray\n",
      " |              Effective alphas of subtree during pruning.\n",
      " |      \n",
      " |          impurities : ndarray\n",
      " |              Sum of the impurities of the subtree leaves for the\n",
      " |              corresponding alpha value in ``ccp_alphas``.\n",
      " |  \n",
      " |  decision_path(self, X, check_input=True)\n",
      " |      Return the decision path in the tree.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator CSR matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |  \n",
      " |  get_depth(self)\n",
      " |      Return the depth of the decision tree.\n",
      " |      \n",
      " |      The depth of a tree is the maximum distance between the root\n",
      " |      and any leaf.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self.tree_.max_depth : int\n",
      " |          The maximum depth of the tree.\n",
      " |  \n",
      " |  get_n_leaves(self)\n",
      " |      Return the number of leaves of the decision tree.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self.tree_.n_leaves : int\n",
      " |          Number of leaves.\n",
      " |  \n",
      " |  predict(self, X, check_input=True)\n",
      " |      Predict class or regression value for X.\n",
      " |      \n",
      " |      For a classification model, the predicted class for each sample in X is\n",
      " |      returned. For a regression model, the predicted value based on X is\n",
      " |      returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes, or the predict values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances.\n",
      " |      \n",
      " |      The importance of a feature is computed as the (normalized) total\n",
      " |      reduction of the criterion brought by that feature.\n",
      " |      It is also known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          Normalized total reduction of criteria by feature\n",
      " |          (Gini importance).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# call help of DecisionTreeRegressor\n",
    "help(DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd747a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestRegressor in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestRegressor(ForestRegressor)\n",
      " |  RandomForestRegressor(n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest regressor.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of classifying\n",
      " |  decision trees on various sub-samples of the dataset and uses averaging\n",
      " |  to improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"squared_error\", \"absolute_error\", \"poisson\"},             default=\"squared_error\"\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"squared_error\" for the mean squared error, which is equal to\n",
      " |      variance reduction as feature selection criterion, \"absolute_error\"\n",
      " |      for the mean absolute error, and \"poisson\" which uses reduction in\n",
      " |      Poisson deviance to find splits.\n",
      " |      Training using \"absolute_error\" is significantly slower\n",
      " |      than when using \"squared_error\".\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |         Poisson criterion.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          Criterion \"mse\" was deprecated in v1.0 and will be removed in\n",
      " |          version 1.2. Use `criterion=\"squared_error\"` which is equivalent.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          Criterion \"mae\" was deprecated in v1.0 and will be removed in\n",
      " |          version 1.2. Use `criterion=\"absolute_error\"` which is equivalent.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `round(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=n_features`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool, default=False\n",
      " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
      " |      Only available if bootstrap=True.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  base_estimator_ : DecisionTreeRegressor\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeRegressor\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          Attribute `n_features_` was deprecated in version 1.0 and will be\n",
      " |          removed in 1.2. Use `n_features_in_` instead.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_prediction_ : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |      Prediction computed with out-of-bag estimate on the training set.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  sklearn.tree.DecisionTreeRegressor : A decision tree regressor.\n",
      " |  sklearn.ensemble.ExtraTreesRegressor : Ensemble of extremely randomized\n",
      " |      tree regressors.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  The default value ``max_features=\"auto\"`` uses ``n_features``\n",
      " |  rather than ``n_features / 3``. The latter was originally suggested in\n",
      " |  [1], whereas the former was more recently justified empirically in [2].\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
      " |         trees\", Machine Learning, 63(1), 3-42, 2006.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestRegressor\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  >>> X, y = make_regression(n_features=4, n_informative=2,\n",
      " |  ...                        random_state=0, shuffle=False)\n",
      " |  >>> regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  RandomForestRegressor(...)\n",
      " |  >>> print(regr.predict([[0, 0, 0, 0]]))\n",
      " |  [-8.32987858]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestRegressor\n",
      " |      ForestRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestRegressor:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict regression target for X.\n",
      " |      \n",
      " |      The predicted regression target of an input sample is computed as the\n",
      " |      mean predicted regression targets of the trees in the forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  n_features_\n",
      " |      DEPRECATED: Attribute `n_features_` was deprecated in version 1.0 and will be removed in 1.2. Use `n_features_in_` instead.\n",
      " |      \n",
      " |      Number of features when fitting the estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __annotations__ = {'_required_parameters': typing.List[str]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# call help of RandomForestRegressor\n",
    "help(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f9ef5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 4: Model Development - Default Hyperparameters</h3>\n",
    "Run each of your selected models using three (3) respective default hyperparameters that you feel would be good candidates for optimization, printing their R-Square values for the training and testing sets. Use as many cells as needed and make sure to label your default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c074ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score : 0.8523\n",
      "Testing Score  : 0.8324\n",
      "Train-Test Gap : 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeRegressor default\n",
    "\n",
    "#define name of model\n",
    "model_name_dtr = 'Decision_Tree_Regression_default'\n",
    "\n",
    "# using DecisionTreeRegressor and define hyperparameters\n",
    "model_dtr = DecisionTreeRegressor(criterion        = 'mse',\n",
    "                                  max_depth        = 7,\n",
    "                                  min_samples_leaf = 25)\n",
    "    \n",
    "#fitting to the train data\n",
    "model_dtr_fit = model_dtr.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# predicting \n",
    "model_dtr_pred = model_dtr.predict(x_test)\n",
    "\n",
    "\n",
    "# data scoring\n",
    "model_dtr_train_score = model_dtr.score(x_train, y_train).round(4) # using R-square\n",
    "model_dtr_test_score  = model_dtr.score(x_test, y_test).round(4)   # using R-square\n",
    "model_dtr_gap         = abs(model_dtr_train_score - model_dtr_test_score).round(4)\n",
    "\n",
    "\n",
    "# showing results\n",
    "print('Training Score :', model_dtr_train_score)\n",
    "print('Testing Score  :', model_dtr_test_score)\n",
    "print('Train-Test Gap :', model_dtr_gap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd4b92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score : 0.8835\n",
      "Testing Score  : 0.8588\n",
      "Train-Test Gap : 0.0247\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor default\n",
    "\n",
    "#define name of model\n",
    "model_rf_name = 'Random_Forest_Regression_default'\n",
    "\n",
    "# using RandomForestRegressor and define hyperparameters\n",
    "model_rf = RandomForestRegressor(criterion        = 'mse',\n",
    "                                 max_depth        = 15,\n",
    "                                 min_samples_leaf = 15)\n",
    "                                \n",
    "\n",
    "#fitting to the train data\n",
    "model_rf_fit = model_rf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# data predicting \n",
    "model_rf_pred = model_rf.predict(x_test)\n",
    "\n",
    "\n",
    "# data scoring\n",
    "model_rf_train_score = model_rf.score(x_train, y_train).round(4) # using R-square\n",
    "model_rf_test_score  = model_rf.score(x_test, y_test).round(4)   # using R-square\n",
    "model_rf_gap         = abs(model_rf_train_score - model_rf_test_score).round(4)\n",
    "\n",
    "\n",
    "# showing results\n",
    "print('Training Score :', model_rf_train_score)\n",
    "print('Testing Score  :', model_rf_test_score)\n",
    "print('Train-Test Gap :', model_rf_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf81be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 5: Hyperparameter Tuning Part I</h3><br>\n",
    "Develop ranges for each of the hyperparameters you would like tune. Write a code to calculate how many models you are building (based on the combinations of hyperparameters you are tuning).\n",
    "<br><br>\n",
    "<strong>Requirement:</strong> You must tune at least three hyperparameters per model.<br>\n",
    "<strong>Recommendation:</strong> Keep the number of models (i.e., iterations) you are building to:\n",
    "\n",
    "* Less than 2,000 for Random Forest and GBM  (not including cross-validation)\n",
    "* Less than 10,000 for all other model types (not including cross-validation)\n",
    "\n",
    "Insert as many code cells as you need for the number of model types you are tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b153ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter of DecisionTreeRegressor\n",
    "dtr_criterion_range = [\"mse\", \"friedman_mse\", \"mae\", \"poisson\"]\n",
    "dtr_depth_range     = np.arange(1, 10, 2)\n",
    "dtr_leaf_range      = np.arange(1, 500, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7ff133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter of RandomForestRegressor\n",
    "rf_criterion_range = [\"squared_error\", \"absolute_error\", \"poisson\"]\n",
    "rf_depth_range     = np.arange(1, 9, 2)\n",
    "rf_leaf_range      = np.arange(1, 100, 25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfe6ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 6: Hyperparameter Tuning Part II</h3><br>\n",
    "Create a hyperparameter grid for each of the models you are tuning. Note that this is the dictionary step we conducted in class. Use as many cells as needed for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c3cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter grid of DecisionTreeRegressor\n",
    "dtr_param_grid = {'criterion'        : dtr_criterion_range,\n",
    "                  'max_depth'        : dtr_depth_range,\n",
    "                  'min_samples_leaf' : dtr_leaf_range}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c0cec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter grid of RandomForestRegressor\n",
    "rf_param_grid = {'criterion'        : rf_criterion_range,\n",
    "                 'max_depth'        : rf_depth_range,\n",
    "                 'min_samples_leaf' : rf_leaf_range}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ec44b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 7: Hyperparameter Tuning Part III</h3><br>\n",
    "a) Complete the remaining steps for hyperparameter tuning. While your code runs, observe the processing time it takes to tune. Use as many cells as needed for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3aa9f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 100 is smaller than n_iter=1000. Running 100 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:366: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'min_samples_leaf': 1, 'max_depth': 7, 'criterion': 'mae'}\n",
      "Tuned Training AUC: 0.79\n"
     ]
    }
   ],
   "source": [
    "# using the DecisionTreeRegressor model object without hyperparameters\n",
    "tuned_tree = DecisionTreeRegressor(random_state = 219)\n",
    "\n",
    "# using RandomizedSearchCV and setting hyperparameter\n",
    "tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "                                   param_distributions   = dtr_param_grid,\n",
    "                                   cv                    = 5,\n",
    "                                   n_iter                = 1000,\n",
    "                                   random_state          = 219)\n",
    "\n",
    "# fitting data\n",
    "tuned_tree_cv.fit(x_data, y_data)\n",
    "\n",
    "\n",
    "# showing optimal parameter\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the DecisionTreeRegressor model object without hyperparameters\n",
    "tuned_tree = RandomForestRegressor(random_state = 219)\n",
    "\n",
    "# using RandomizedSearchCV and setting hyperparameter\n",
    "tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "                                   param_distributions   = rf_param_grid,\n",
    "                                   cv                    = 5,\n",
    "                                   random_state          = 219)\n",
    "\n",
    "# fitting data\n",
    "tuned_tree_cv.fit(x_data, y_data)\n",
    "\n",
    "\n",
    "# showing optimal parameter\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc819d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkmbb\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 48 is smaller than n_iter=1000. Running 48 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# using the RandomForestRegressor model object without hyperparameters\n",
    "tuned_tree = RandomForestRegressor(random_state = 219)\n",
    "\n",
    "# using RandomizedSearchCV and setting hyperparameter\n",
    "tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "                                   param_distributions   = rf_param_grid,\n",
    "                                   cv                    = 5,\n",
    "                                   n_iter                = 1000,\n",
    "                                   random_state          = 219)\n",
    "\n",
    "# fitting data\n",
    "tuned_tree_cv.fit(x_data, y_data)\n",
    "\n",
    "\n",
    "# showing optimal parameter\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f22c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3102d91",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>\n",
    "b) Explore the hyperparameter tuning results for one of your tuned models. Look for hyperparameter combinations that tied for first place. Test each of these models using train-test split. If no models tied for first place, test your top three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeRegressor tuned hyperparameter\n",
    "\n",
    "model_name = ' Decision Tree Regressor tuned hyperparameter'\n",
    "\n",
    "# using  DecisionTreeRegressor with optimized hyperparameter\n",
    "model = DecisionTreeRegressor(criterion        = 'mae'\n",
    "                              max_depth        = 7,\n",
    "                              min_samples_leaf = 1)\n",
    "\n",
    "\n",
    "# data fitting\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# data predicting\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# data scoring\n",
    "model_train_score = model.score(x_train, y_train).round(4) # using R-square\n",
    "model_test_score  = model.score(x_test, y_test).round(4)   # using R-square\n",
    "model_gap         = abs(model_train_score - model_test_score).round(4)\n",
    "\n",
    "\n",
    "# showing result\n",
    "print('Training Score :', model_train_score)\n",
    "print('Testing Score  :', model_test_score)\n",
    "print('Train-Test Gap :', model_gap)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor tuned hyperparameter\n",
    "model_name = 'Pruned Random Forest'\n",
    "\n",
    "\n",
    "# using  DecisionTreeRegressor with optimized hyperparameter\n",
    "model = RandomForestRegressor(n_estimators     = 100,\n",
    "                              criterion        = 'mse',\n",
    "                              max_depth        = 4,\n",
    "                              min_samples_leaf = 25,\n",
    "                              bootstrap        = True,\n",
    "                              warm_start       = False,\n",
    "                              random_state     = 219)\n",
    "\n",
    "# data fitting\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# data predicting\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "# data scoring\n",
    "model_train_score = model.score(x_train, y_train).round(4) # using R-square\n",
    "model_test_score  = model.score(x_test, y_test).round(4)   # using R-square\n",
    "model_gap         = abs(model_train_score - model_test_score).round(4)\n",
    "\n",
    "\n",
    "# showing result\n",
    "print('Training Score :', model_train_score)\n",
    "print('Testing Score  :', model_test_score)\n",
    "print('Train-Test Gap :', model_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6f0a9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 8: (optional) Explore Tuned Hyperparameters</h3><br>\n",
    "After tuning, it is a great idea to explore any hyperparameters that were markedly different from their default values once tuned. Investigate the purpose of these hyperparameters in <a href=\"https://scikit-learn.org/stable/index.html\">the scikit-learn documentation</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
